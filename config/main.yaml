defaults:
  #- process: process1  # Selects the default preprocessing pipeline
  #- model: model1      # Selects the default model
  - _self_

# Data paths
data:
  raw: data/raw/data.csv
  processed: data/processed/processed.csv
  final: data/final/final.csv

# Preprocessing settings
preprocessing:
  steps:  # Define which preprocessing steps to apply
    - normalize
    - impute_missing
    - feature_engineering
  impute_method: mean  # Options: mean, median, knn
  scaling: standard    # Options: minmax, standard, robust

# Model selection & hyperparameters
model:
  type: random_forest  # Options: random_forest, xgboost, logistic_regression
  hyperparameters:
    n_estimators: 100
    max_depth: 10
    learning_rate: 0.1
  cross_validation:
    folds: 5
    scoring: accuracy

# Experiment tracking
experiment:
  save_results: true
  output_dir: ../results/
  logging: wandb  # Options: wandb, tensorboard, none

# Hydra 
hydra:
  run:
    dir: ${oc.env:PROJECT_ROOT,.}/results/${now:%Y-%m-%d}/${now:%H-%M-%S}
  job:
    chdir: true
  output_subdir: .hydra


